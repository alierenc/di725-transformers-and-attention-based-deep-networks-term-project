{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alierenc/di725-transformers-and-attention-based-deep-networks-term-project/blob/main/Phase%20III/1.1.%20PaliGemma%20-%20Zero-Shot%20Image%20Captioning%20Inference%20with%20Some%20Outputs%20Cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "hf_token = \" \" # Huggingface token\n",
        "login(token = hf_token)"
      ],
      "metadata": {
        "id": "HxRuDcZeWlmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "id": "ieFLxaGQyKmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
        "from datasets import load_dataset, DatasetDict\n",
        "import torch\n",
        "\n",
        "# Load the dataset of full riscm\n",
        "ds = load_dataset('caglarmert/full_riscm')\n",
        "\n",
        "full = ds[\"train\"]\n",
        "\n",
        "# test   = indices [0, 3150)\n",
        "test_ds = full.select(range(3150))\n",
        "\n",
        "# validation = indices [3150, 6300)\n",
        "val_ds = full.select(range(3150, 6300))\n",
        "\n",
        "# train  = indices [6300, end)\n",
        "train_ds = full.select(range(6300, len(full)))\n",
        "\n",
        "# bundle into a DatasetDict\n",
        "ds = DatasetDict({\n",
        "    \"val\": val_ds,\n",
        "    \"test\": test_ds,\n",
        "    \"train\": train_ds,\n",
        "})\n",
        "\n",
        "# Load the model and the processor\n",
        "model_id = \"google/paligemma-3b-mix-224\"\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id)\n",
        "\n",
        "# Move model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "Z1KNOSns1Okr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# We add <image> token upon the warning.\n",
        "prompt = \"<image> caption en\"\n",
        "predictions = []\n",
        "\n",
        "for i in tqdm(range(len(ds[\"test\"])), desc=\"Generating captions\"):\n",
        "    # Get the image\n",
        "    image = ds[\"test\"][i][\"image\"]\n",
        "\n",
        "    # Preprocess image and prompt\n",
        "    inputs = processor(image, prompt, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move to GPU\n",
        "\n",
        "    # Generate caption\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=30)\n",
        "\n",
        "    # Decode output\n",
        "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
        "    if caption.startswith(prompt):\n",
        "        caption = caption[len(prompt):].strip()\n",
        "\n",
        "    predictions.append(caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anEFJNXxOGzS",
        "outputId": "8c336578-9b92-4a2d-ad21-3e2d61c3b746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating captions: 100%|██████████| 3150/3150 [30:45<00:00,  1.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the references\n",
        "# Define a varible to store the reference captions\n",
        "all_references = []\n",
        "for i in tqdm(range(len(ds[\"test\"])), desc=\"Collecting reference captions\"):\n",
        "    # Get the reference\n",
        "    reference_per_sample = []\n",
        "    for j in range(1,6):\n",
        "        reference = ds[\"test\"][i][f\"caption_{j}\"]\n",
        "        reference_per_sample.append(reference)\n",
        "        print(f\"The reference caption_{j}:\")\n",
        "        print(repr(reference))\n",
        "\n",
        "    print()\n",
        "    all_references.append(reference_per_sample)"
      ],
      "metadata": {
        "id": "Ial5sVoWBNqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the format of the reference captions\n",
        "print(all_references[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtqWQf7DEKl4",
        "outputId": "a4b71453-ec27-4147-966c-493d3c67122e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['A gray plane on the runway and the lawn beside .', 'A grey plane is on the runway by the lawn .', 'There is an airplane on the runway with a large lawn by the runway .', 'A plane is parked on the runway next to the grass .', 'There is a plane on the runway beside the grass .'], ['Three small planes parked in a line on the airport and a big plane behind them .', 'There are four aircraft on the open ground, The largest of which is three times as large as the smallest one .', 'There are many planes of different sizes in a clearing .', 'Four planes are parked on the runway .', 'Four planes of different sizes were on the marked ground .'], ['A plane parked in a line on the airport with some marks .', 'A white plane was parked on the instruction line .', 'An airplane parked in an open area with many containers next to it .', 'A plane is parked on the open space .', 'There is 1 plane on the ground marked .'], ['A small plane and a big plane parked next to boarding bridges .', 'A white plane and a gray plane parked at the boarding port  The white plane was about four times as large as the gray one .', 'Two planes of different sizes are neatly parked next to the buildings in the airport .', 'A large plane and a small plane are parked near the terminal .', 'Two planes are on the marked ground .'], ['Two planes parked next to boarding bridges .', 'Two aircraft were parked at the departure gates .', 'Two planes of different sizes are neatly parked next to the buildings in the airport .', 'Two planes are parked next to the terminal .', 'Two planes are on the marked ground .']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the format of the predicted captions. Each sample starts with \" caption en\\n\". This can be better seen when the code is rerun.\n",
        "print(predictions[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hS827PUEhRN",
        "outputId": "61835336-d954-44fe-e73a-dc26e799242c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"A large jetliner sits proudly on the runway, its powerful engines roaring. The plane's wing extends gracefully, while the tail gracefully curves upward.\", 'A group of four airplanes are parked on a runway, their wings resting on the ground. The runway is made of concrete and has white lines painted on', \"A large jetliner sits proudly on the tarmac, its powerful engines idling. The plane's tail and wing extend gracefully, while the white lines on\", 'An aerial view of an airport with several planes parked at gates. The tarmac is gray, and the runway is also gray. There are several jet bridges', 'Two airplanes are parked on the tarmac at an airport. The planes are white, with red and white stripes on their tails. The wing of the plane']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to clean the new lines from the predicted captions for a better evaluation at later stages\n",
        "for i in range(len(predictions)):\n",
        "    predictions[i] = predictions[i].lstrip(\"\\n\")\n",
        "    predictions[i] = predictions[i].lstrip(\" caption en\\n\")\n",
        "\n",
        "predictions[:5]"
      ],
      "metadata": {
        "id": "33Bgq6tnE0Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9ee334-07ff-4b9e-d062-5a41ffd9bf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"A large jetliner sits proudly on the runway, its powerful engines roaring. The plane's wing extends gracefully, while the tail gracefully curves upward.\",\n",
              " 'A group of four airplanes are parked on a runway, their wings resting on the ground. The runway is made of concrete and has white lines painted on',\n",
              " \"A large jetliner sits proudly on the tarmac, its powerful engines idling. The plane's tail and wing extend gracefully, while the white lines on\",\n",
              " 'An aerial view of an airport with several planes parked at gates. The tarmac is gray, and the runway is also gray. There are several jet bridges',\n",
              " 'Two airplanes are parked on the tarmac at an airport. The planes are white, with red and white stripes on their tails. The wing of the plane']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize references and predictions:\n",
        "tokenized_refs = [\n",
        "    [nltk.word_tokenize(ref.lower()) for ref in refs]\n",
        "    for refs in all_references\n",
        "]\n",
        "\n",
        "tokenized_hyps = [nltk.word_tokenize(pred.lower()) for pred in predictions]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6-ypijV2XMP",
        "outputId": "010690ff-22ed-4f0c-e613-2e8fcf37325c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_refs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HVsAM-UjEtN",
        "outputId": "b72ded6c-35c7-49ee-f2f1-4a96ccac7b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a',\n",
              "  'gray',\n",
              "  'plane',\n",
              "  'on',\n",
              "  'the',\n",
              "  'runway',\n",
              "  'and',\n",
              "  'the',\n",
              "  'lawn',\n",
              "  'beside',\n",
              "  '.'],\n",
              " ['a', 'grey', 'plane', 'is', 'on', 'the', 'runway', 'by', 'the', 'lawn', '.'],\n",
              " ['there',\n",
              "  'is',\n",
              "  'an',\n",
              "  'airplane',\n",
              "  'on',\n",
              "  'the',\n",
              "  'runway',\n",
              "  'with',\n",
              "  'a',\n",
              "  'large',\n",
              "  'lawn',\n",
              "  'by',\n",
              "  'the',\n",
              "  'runway',\n",
              "  '.'],\n",
              " ['a',\n",
              "  'plane',\n",
              "  'is',\n",
              "  'parked',\n",
              "  'on',\n",
              "  'the',\n",
              "  'runway',\n",
              "  'next',\n",
              "  'to',\n",
              "  'the',\n",
              "  'grass',\n",
              "  '.'],\n",
              " ['there',\n",
              "  'is',\n",
              "  'a',\n",
              "  'plane',\n",
              "  'on',\n",
              "  'the',\n",
              "  'runway',\n",
              "  'beside',\n",
              "  'the',\n",
              "  'grass',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence-level BLEU-2\n",
        "smooth = SmoothingFunction().method1\n",
        "for i, (refs_per_sample, hyp_tok) in enumerate(zip(tokenized_refs, tokenized_hyps)):\n",
        "    scores = []\n",
        "    for refs_tok in refs_per_sample:\n",
        "        score = sentence_bleu(\n",
        "            [refs_tok],\n",
        "            hyp_tok,\n",
        "            weights=(1/2, 1/2),\n",
        "            smoothing_function=smooth\n",
        "        )\n",
        "        scores.append(score)\n",
        "    max_score = max(scores)\n",
        "    print(f\"Example {i+1:2d} BLEU-2: {max_score*100:.2f}\")"
      ],
      "metadata": {
        "id": "e9BGh1zclFI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus-level BLEU-2\n",
        "# corpus_bleu expects list-of-list-of-tokens refs, and list-of-tokens hyps\n",
        "corpus_score = corpus_bleu(\n",
        "    tokenized_refs,\n",
        "    tokenized_hyps,\n",
        "    weights=(1/2, 1/2),\n",
        "    smoothing_function=smooth\n",
        ")\n",
        "print(f\"\\nCorpus BLEU-2: {corpus_score*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJwuHsapXUdJ",
        "outputId": "5579226a-0cc6-4a77-d4d7-5f6f1f8613fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Corpus BLEU-2: 18.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence-level BLEU-3\n",
        "smooth = SmoothingFunction().method1\n",
        "for i, (refs_per_sample, hyp_tok) in enumerate(zip(tokenized_refs, tokenized_hyps)):\n",
        "    scores = []\n",
        "    for refs_tok in refs_per_sample:\n",
        "        score = sentence_bleu(\n",
        "            [refs_tok],\n",
        "            hyp_tok,\n",
        "            weights=(1/3, 1/3, 1/3),\n",
        "            smoothing_function=smooth\n",
        "        )\n",
        "        scores.append(score)\n",
        "    max_score = max(scores)\n",
        "    print(f\"Example {i+1:2d} BLEU-3: {max_score*100:.2f}\")"
      ],
      "metadata": {
        "id": "BOQ1uwXglOJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus-level BLEU-3\n",
        "# corpus_bleu expects list-of-list-of-tokens refs, and list-of-tokens hyps\n",
        "corpus_score = corpus_bleu(\n",
        "    tokenized_refs,\n",
        "    tokenized_hyps,\n",
        "    weights=(1/3, 1/3, 1/3),\n",
        "    smoothing_function=smooth\n",
        ")\n",
        "print(f\"\\nCorpus BLEU-3: {corpus_score*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOO3sbozXR1g",
        "outputId": "20102e5b-53b0-460b-9abb-49cbffccbd54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Corpus BLEU-3: 8.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence-level BLEU-4\n",
        "smooth = SmoothingFunction().method1\n",
        "for i, (refs_per_sample, hyp_tok) in enumerate(zip(tokenized_refs, tokenized_hyps)):\n",
        "    scores = []\n",
        "    for refs_tok in refs_per_sample:\n",
        "        score = sentence_bleu(\n",
        "            [refs_tok],\n",
        "            hyp_tok,\n",
        "            weights=(1/4, 1/4, 1/4, 1/4),\n",
        "            smoothing_function=smooth\n",
        "        )\n",
        "        scores.append(score)\n",
        "    max_score = max(scores)\n",
        "    print(f\"Example {i+1:2d} BLEU-4: {max_score*100:.2f}\")"
      ],
      "metadata": {
        "id": "52GwUtcJk_ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus-level BLEU-4\n",
        "# corpus_bleu expects list-of-list-of-tokens refs, and list-of-tokens hyps\n",
        "corpus_score = corpus_bleu(\n",
        "    tokenized_refs,\n",
        "    tokenized_hyps,\n",
        "    weights=(1/4, 1/4, 1/4, 1/4),\n",
        "    smoothing_function=smooth\n",
        ")\n",
        "print(f\"\\nCorpus BLEU-4: {corpus_score*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASDp-WOxXRA_",
        "outputId": "69845611-1f39-4770-d7e2-2e854a2dfc7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Corpus BLEU-4: 4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Go on to calculate ROUGE scores\n",
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "HFe4Ho28BBA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235e7354-1da8-465f-9f69-205389f3938b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "# Ensure tokenizer\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "def rouge_n(ref: str, hyp: str, n: int = 4):\n",
        "    ref_toks = nltk.word_tokenize(ref.lower())\n",
        "    hyp_toks = nltk.word_tokenize(hyp.lower())\n",
        "    ref_ngrams = list(nltk.ngrams(ref_toks, n))\n",
        "    hyp_ngrams = list(nltk.ngrams(hyp_toks, n))\n",
        "    ref_counts = Counter(ref_ngrams)\n",
        "    hyp_counts = Counter(hyp_ngrams)\n",
        "    overlap = sum(min(ref_counts[ng], hyp_counts[ng]) for ng in ref_counts)\n",
        "    recall = overlap / max(len(ref_ngrams), 1)\n",
        "    precision = overlap / max(len(hyp_ngrams), 1)\n",
        "    f1 = 2 * recall * precision / (recall + precision + 1e-8)\n",
        "    return (recall, precision, f1)\n",
        "\n",
        "\n",
        "# Compute ROUGE-2\n",
        "all_recalls, all_precisions, all_f1s = [], [], []\n",
        "for refs, pred in zip(all_references, predictions):\n",
        "    recalls_per_sample, precisions_per_sample, f1s_per_sample = [], [], []\n",
        "    for ref in refs:\n",
        "        r, p, f = rouge_n(ref, pred, n=2)\n",
        "        recalls_per_sample.append(r)\n",
        "        precisions_per_sample.append(p)\n",
        "        f1s_per_sample.append(f)\n",
        "\n",
        "    max_score = max(f1s_per_sample)\n",
        "    max_index = f1s_per_sample.index(max_score)\n",
        "    all_recalls.append(recalls_per_sample[max_index])\n",
        "    all_precisions.append(precisions_per_sample[max_index])\n",
        "    all_f1s.append(f1s_per_sample[max_index])\n",
        "    print(f\"REF:  {refs[max_index]!r}\")\n",
        "    print(f\"HYP:  {pred!r}\")\n",
        "    print(f\"   ROUGE-2 Recall:    {recalls_per_sample[max_index]*100:.2f}\")\n",
        "    print(f\"   ROUGE-2 Precision: {precisions_per_sample[max_index]*100:.2f}\")\n",
        "    print(f\"   ROUGE-2 F1:        {f1s_per_sample[max_index]*100:.2f}\\n\")"
      ],
      "metadata": {
        "id": "ndmk9F4VaR9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report overall averages\n",
        "avg_r = sum(all_recalls) / len(all_recalls)\n",
        "avg_p = sum(all_precisions) / len(all_precisions)\n",
        "avg_f = sum(all_f1s) / len(all_f1s)\n",
        "print(\"=== AVERAGE ROUGE-2 METRICS ===\")\n",
        "print(f\"Recall:    {avg_r*100:.2f}\")\n",
        "print(f\"Precision: {avg_p*100:.2f}\")\n",
        "print(f\"F1:        {avg_f*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXKVnSURXYuh",
        "outputId": "c4d40759-2e26-4d46-969f-888cd26ecb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AVERAGE ROUGE-2 METRICS ===\n",
            "Recall:    10.81\n",
            "Precision: 5.30\n",
            "F1:        6.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute ROUGE-3\n",
        "all_recalls, all_precisions, all_f1s = [], [], []\n",
        "for refs, pred in zip(all_references, predictions):\n",
        "    recalls_per_sample, precisions_per_sample, f1s_per_sample = [], [], []\n",
        "    for ref in refs:\n",
        "        r, p, f = rouge_n(ref, pred, n=3)\n",
        "        recalls_per_sample.append(r)\n",
        "        precisions_per_sample.append(p)\n",
        "        f1s_per_sample.append(f)\n",
        "\n",
        "    max_score = max(f1s_per_sample)\n",
        "    max_index = f1s_per_sample.index(max_score)\n",
        "    all_recalls.append(recalls_per_sample[max_index])\n",
        "    all_precisions.append(precisions_per_sample[max_index])\n",
        "    all_f1s.append(f1s_per_sample[max_index])\n",
        "    print(f\"REF:  {refs[max_index]!r}\")\n",
        "    print(f\"HYP:  {pred!r}\")\n",
        "    print(f\"   ROUGE-3 Recall:    {recalls_per_sample[max_index]*100:.2f}\")\n",
        "    print(f\"   ROUGE-3 Precision: {precisions_per_sample[max_index]*100:.2f}\")\n",
        "    print(f\"   ROUGE-3 F1:        {f1s_per_sample[max_index]*100:.2f}\\n\")"
      ],
      "metadata": {
        "id": "A3iJDsYWmLq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report overall averages\n",
        "avg_r = sum(all_recalls) / len(all_recalls)\n",
        "avg_p = sum(all_precisions) / len(all_precisions)\n",
        "avg_f = sum(all_f1s) / len(all_f1s)\n",
        "print(\"=== AVERAGE ROUGE-3 METRICS ===\")\n",
        "print(f\"Recall:    {avg_r*100:.2f}\")\n",
        "print(f\"Precision: {avg_p*100:.2f}\")\n",
        "print(f\"F1:        {avg_f*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H-KTzuEXd1w",
        "outputId": "7e9b0b58-5a65-4bfa-aff0-5d4524f3204b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AVERAGE ROUGE-3 METRICS ===\n",
            "Recall:    3.17\n",
            "Precision: 1.38\n",
            "F1:        1.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute ROUGE-4\n",
        "all_recalls, all_precisions, all_f1s = [], [], []\n",
        "for refs, pred in zip(all_references, predictions):\n",
        "    recalls_per_sample, precisions_per_sample, f1s_per_sample = [], [], []\n",
        "    for ref in refs:\n",
        "        r, p, f = rouge_n(ref, pred, n=4)\n",
        "        recalls_per_sample.append(r)\n",
        "        precisions_per_sample.append(p)\n",
        "        f1s_per_sample.append(f)\n",
        "\n",
        "    max_score = max(f1s_per_sample)\n",
        "    max_index = f1s_per_sample.index(max_score)\n",
        "    all_recalls.append(recalls_per_sample[max_index])\n",
        "    all_precisions.append(precisions_per_sample[max_index])\n",
        "    all_f1s.append(f1s_per_sample[max_index])\n",
        "    print(f\"REF:  {refs[max_index]!r}\")\n",
        "    print(f\"HYP:  {pred!r}\")\n",
        "    print(f\"   ROUGE-4 Recall:    {recalls_per_sample[max_index]*100:.2f}\")\n",
        "    print(f\"   ROUGE-4 Precision: {precisions_per_sample[max_index]*100:.2f}\")\n",
        "    print(f\"   ROUGE-4 F1:        {f1s_per_sample[max_index]*100:.2f}\\n\")"
      ],
      "metadata": {
        "id": "-GbFHU6QnYuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Report overall averages\n",
        "avg_r = sum(all_recalls) / len(all_recalls)\n",
        "avg_p = sum(all_precisions) / len(all_precisions)\n",
        "avg_f = sum(all_f1s) / len(all_f1s)\n",
        "print(\"=== AVERAGE ROUGE-4 METRICS ===\")\n",
        "print(f\"Recall:    {avg_r*100:.2f}\")\n",
        "print(f\"Precision: {avg_p*100:.2f}\")\n",
        "print(f\"F1:        {avg_f*100:.2f}\")"
      ],
      "metadata": {
        "id": "5MlAOzLHs9je",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1578b71-c606-4ee4-bd1f-7040753b603a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AVERAGE ROUGE-4 METRICS ===\n",
            "Recall:    0.71\n",
            "Precision: 0.31\n",
            "F1:        0.39\n"
          ]
        }
      ]
    }
  ]
}